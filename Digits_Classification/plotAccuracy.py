__author__ = 'gaobrook'

from config import *

dimList = [25, 50, 100, 150, 200, 300, 450, 600, 784]

#######accuracy
#svm
poly = [93.875, 94.975, 95.35, 95.9, 95.4, 93.575, 90.875, 90.05, 91.5]
linear = [86.05, 87.55, 86.375, 84.55, 83.925, 83.975, 85.05, 84.925, 84.925]
rbf = [95.275, 95.85, 95.45, 95.55, 95.625, 95.525, 95.55, 95.475, 95.475]

##knn
KNN1 = [92.675, 92.825, 92.2, 91.875, 91.775, 91.775, 91.6, 91.625, 91.625]
KNN2 = [91.325, 91.375, 90.15, 90.0, 89.8, 89.5, 89.3, 89.25, 89.25]
KNN4 = [92.9, 92.375, 91.625, 91.4, 91.35, 91.125, 90.925, 90.9, 90.9]


####bayes
MultinomialNB = [81.175, 83.55, 83.875, 83.6, 83.675, 83, 82.4, 82.35, 82.35]
GaussianNB = [85.775, 85.95, 84.475, 83.45, 82.675, 79.15, 66.55, 51.25, 59.125]
BernoulliNB = [68.95, 71.35, 70.725, 70.1, 69.575, 65.825, 62.7, 59.375, 82.3]



########time
#svm
poly_t = [1.8441165, 2.8774725, 5.530067, 8.406747, 11.5312125, 17.3749345, 26.645719, 35.5270995, 17.0199725]
linear_t = [2.8413465, 3.4188215, 4.752619, 4.245475, 4.5723145, 5.9738985, 8.095593, 10.2730805, 11.8629045]
rbf_t = [1.850789, 2.829562, 5.022589, 7.0633485, 9.194177, 13.927273, 20.965697, 27.951346, 35.778166]

KNN1_t = [2.0935915, 2.4643025, 3.4909335, 3.9390505, 4.483948, 5.3860905, 7.184459, 10.620525, 6.8394355]
KNN2_t = [2.07596, 2.72083, 3.6878645, 4.4347615, 5.2330635, 5.728212, 7.961722, 10.0970375, 8.366255]
KNN4_t = [2.5734465, 2.802948, 4.037164, 4.614712, 5.007371, 6.449648, 8.0332, 9.319763, 7.774253]

MultinomialNB_t = [1.0752575, 1.205738, 1.151526, 1.2250355, 1.196426, 1.225929, 1.2084405, 1.2413335, 0.055578]
GaussianNB_t = [1.223989, 1.2899555, 1.107695, 1.181359, 1.0897525, 1.273688, 1.2433385, 1.2335055, 0.282355]
BernoulliNB_t = [1.034903, 1.0340545, 1.101908, 1.0971005, 1.0910415, 1.1030915, 1.1189635, 1.1355935, 0.0839255]




title = "Accuracy fluctuation with dimension"
plt.figure()
plt.title(title)
plt.plot(dimList, poly, "r^-", label="SVM_POLY", linewidth=2)
plt.plot(dimList, linear, "g^-", label="SVM_LINEAR", linewidth=2)
plt.plot(dimList, rbf, "b^-", label="SVM_RBF", linewidth=2)
plt.plot(dimList, KNN1, "cs--", label="KNN-1", linewidth=2)
plt.plot(dimList, KNN2, "ks--", label="KNN-2", linewidth=2)
plt.plot(dimList, KNN4, "ms--", label="KNN-4", linewidth=2)
plt.plot(dimList, MultinomialNB, "ro-.", label="MultinomialNB", linewidth=2.5)
plt.plot(dimList, GaussianNB, "go-.", label="GaussianNB", linewidth=2.5)
plt.plot(dimList, BernoulliNB, "bo-.", label="BernoulliNB", linewidth=2.5)
plt.ylabel("Accuracy(%)")
plt.xlabel("Dimension")
plt.ylim(50, 100)
plt.xlim(0, 800)
#plt.legend(loc='center left', bbox_to_anchor=(0.5, -0.05),
#          fancybox=True, shadow=True, ncol=5)
plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=10)
#plt.legend(loc=1)
plt.grid(True)
plt.show()



########challenge
#poly
{0: [[0.56, 0.54, 0.54, 0.5, 0.48, 0.46, 0.46, 0.46, 0.46]], 1: [[0.52, 0.5, 0.5, 0.54, 0.54, 0.52, 0.42, 0.42, 0.46]]}
#linear
{0: [[0.4, 0.46, 0.5, 0.54, 0.56, 0.44, 0.48, 0.48, 0.48]], 1: [[0.36, 0.44, 0.4, 0.4, 0.34, 0.42, 0.44, 0.42, 0.42]]}
#rbf
{0: [[0.52, 0.6, 0.64, 0.6, 0.6, 0.6, 0.6, 0.56, 0.6]], 1: [[0.54, 0.5, 0.56, 0.54, 0.54, 0.52, 0.54, 0.54, 0.54]]}


####Bayes
#MultinomialNB
0: [0.32, 0.38, 0.48, 0.44, 0.36, 0.4, 0.44, 0.44, 0.54]
1: [0.4, 0.42, 0.42, 0.36, 0.42, 0.4, 0.44, 0.42, 0.54]
#GaussianNB
0: [0.3, 0.3, 0.42, 0.44, 0.42, 0.4, 0.42, 0.46, 0.36]
1: [0.42, 0.34, 0.44, 0.38, 0.34, 0.38, 0.48, 0.4, 0.42]
#BernoulliNB
0: [0.24, 0.32, 0.44, 0.4, 0.36, 0.36, 0.34, 0.36, 0.56]
1: [0.34, 0.32, 0.34, 0.28, 0.32, 0.26, 0.34, 0.3, 0.56]


####KNN
#1KK
0: [0.6, 0.44, 0.42, 0.4, 0.4, 0.38, 0.36, 0.36, 0.36]
1: [0.42, 0.38, 0.36, 0.34, 0.34, 0.34, 0.34, 0.34, 0.34]
#2KK
0: [0.48, 0.36, 0.38, 0.34, 0.34, 0.36, 0.34, 0.32, 0.32]
1: [0.48, 0.44, 0.46, 0.4, 0.4, 0.44, 0.42, 0.42, 0.42]
#4KK
0: [0.4, 0.34, 0.36, 0.34, 0.32, 0.34, 0.34, 0.34, 0.34]
1: [0.42, 0.44, 0.4, 0.4, 0.42, 0.4, 0.36, 0.34, 0.34]




#########Accuracy
####svm
#poly
{0: [[0.938, 0.9525, 0.9555, 0.959, 0.9575, 0.9425, 0.917, 0.9065, 0.9205]],
 1: [[0.9395, 0.947, 0.9515, 0.959, 0.9505, 0.929, 0.9005, 0.8945, 0.9095]]}
#linear
{0: [[0.865, 0.883, 0.8665, 0.8535, 0.84, 0.842, 0.8485, 0.846, 0.846]],
 1: [[0.856, 0.868, 0.861, 0.8375, 0.8385, 0.8375, 0.8525, 0.8525, 0.8525]]}
#rbf
{0: [[0.9515, 0.96, 0.9545, 0.956, 0.9575, 0.957, 0.958, 0.957, 0.958]],
 1: [[0.954, 0.957, 0.9545, 0.955, 0.955, 0.9535, 0.953, 0.9525, 0.9515]]}

####KNN
#1NN
{0: [[0.928, 0.9285, 0.9225, 0.9175, 0.915, 0.9155, 0.9135, 0.914, 0.914]],
 1: [[0.9255, 0.928, 0.9215, 0.92, 0.9205, 0.92, 0.9185, 0.9185, 0.9185]]}
#2NN
{0: [[0.9145, 0.911, 0.9, 0.8995, 0.8955, 0.891, 0.8875, 0.8875, 0.8875]],
 1: [[0.912, 0.9165, 0.903, 0.9005, 0.9005, 0.899, 0.8985, 0.8975, 0.8975]]}
#3NN
{0: [[0.932, 0.928, 0.9195, 0.9175, 0.9155, 0.912, 0.9095, 0.909, 0.909]],
 1: [[0.926, 0.9195, 0.913, 0.9105, 0.9115, 0.9105, 0.909, 0.909, 0.909]]}

####Bayes
#MultinomialNB
{0: [[0.819, 0.8375, 0.8435, 0.841, 0.8445, 0.8325, 0.8245, 0.8255, 0.823]],
 1: [[0.8045, 0.8335, 0.834, 0.831, 0.829, 0.8275, 0.8235, 0.8215, 0.8085]]}
#GaussianNB
{0: [[0.8595, 0.8635, 0.8435, 0.838, 0.833, 0.7895, 0.683, 0.538, 0.6155]],
 1: [[0.856, 0.8555, 0.846, 0.831, 0.8205, 0.7935, 0.648, 0.487, 0.567]]}
#BernoulliNB
{0: [[0.6995, 0.7205, 0.713, 0.7045, 0.699, 0.6615, 0.6185, 0.594, 0.8235]],
 1: [[0.6795, 0.7065, 0.7015, 0.6975, 0.6925, 0.655, 0.6355, 0.5935, 0.8225]]}